primehub:
  mode: ce
  scheme: http
  keycloak:
    scheme: http
    domain:
    #port:
    username: keycloak
    password:
    realm: primehub
    everyoneGroupId:
    clientId: admin-ui
    #rolePrefix:
    #maxSockets:
    #maxFreeSockets:
  sharedVolumeStorageClass: ""
  store:
    enabled: false
    bucket: primehub

ingress:
  enabled: true
  annotations:
    ingress.kubernetes.io/affinity: cookie
    kubernetes.io/ingress.class: nginx
    kubernetes.io/tls-acme: "true"
  hosts:
    - chart-example.local
  tls: []

# Primehub console
console:
  enableUserPortal: true
  replicas: 1
  image:
    repository: infuseai/primehub-console
    tag: latest
    pullPolicy: Always
    # credentials:
    #   registry: registry.gitlab.com
    #   username:
    #   password:

  url: https://example.com/
  graphqlEndpoint: /graphql
  #locale: en
  portalConfig: null
    # services:
    #   Service portal setup example:
    #   - name: Example
    #     uri: "https://example.com"
    #     image: "/console/default-covers/default.png"
    #     adminOnly: true | false
    #   - name: Gitlab
    #    uri: "https://gitlab.com/infuseai"
    #    image: "/console/default-covers/gitlab.png"
    #   - name: JupyterHub
    #     uri: "/hub"
    #     image: "/console/default-covers/jupyter.png"
    #   - name: User Guide
    #     uri: "https://infuseai.zendesk.com/hc/en-us"
    #     image: "/console/default-covers/support.png"
    #   - name: JupyterHub Admin
    #     uri: "/hub/admin"
    #     adminOnly: true
    #     image: "/console/default-covers/jh-admin.png"
    #   - name: Admin Dashboard
    #     uri: "/console/cms"
    #     image: "/console/default-covers/admin-ui.png"
    #     adminOnly: true
    #   - name: Maintenance Notebook
    #     uri: "/maintenance"
    #     image: "/console/default-covers/notebook.png"
    #     adminOnly: true
    #   - name: Grafana
    #     uri: "/grafana/login/generic_oauth"
    #     image: "/grafana/public/img/grafana_icon.svg"
    #     adminOnly: true
    # welcomeMessage: >

  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

graphql:
  replicas: 1
  image:
    repository: infuseai/primehub-console-graphql
    tag: latest
    pullPolicy: Always
    # credentials:
    #   registry: registry.gitlab.com
    #   username:
    #   password:
  sharedGraphqlSecret:
  #playgroundEnabled: false

  service:
    type: ClusterIP
    port: 80
    targetPort: 3001
  resources:
    limits:
      cpu: 1000m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 512Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

watcher:
  image:
    repository: infuseai/primehub-console-watcher
    tag: latest
    pullPolicy: Always
    # credentials:
    #   registry: registry.gitlab.com
    #   username:
    #   password:
  resources:
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi

# Admisson
admission:
  enabled: true
  image:
    repository: infuseai/primehub-admission
    tag: "29c8243d73"
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 1000m
      memory: 256Mi
    requests:
      cpu: 128m
      memory: 128Mi
  postHook:
    resources:
      limits:
        cpu: 200m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi

# Bootstrap
bootstrap:
  enabled: true
  image:
    repository: infuseai/primehub-bootstrap
    tag: "20191022"
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 500m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi
  username: phadmin
  password:
  group: phusers

# Dataset upload
datasetUpload:
  enabled: true
  interface:
    replicas: 1
    webFrontEndImage:
      repository: infuseai/dataset-upload-web-front-end
      tag: d744507a5e
      pullPolicy: IfNotPresent
      resources:
        limits:
          cpu: 200m
          memory: 256Mi
        requests:
          cpu: 200m
          memory: 256Mi
    tusdImage:
      repository: infuseai/tusd
      tag: 0.1.1
      pullPolicy: IfNotPresent
      resources:
        limits:
          cpu: 200m
          memory: 128Mi
        requests:
          cpu: 200m
          memory: 128Mi
  metacontrollerHooks:
    replicas: 1
    image:
      repository: metacontroller/jsonnetd
      tag: 0.1
      pullPolicy: IfNotPresent
    resources:
      limits:
        cpu: 50m
        memory: 128Mi
      requests:
        cpu: 50m
        memory: 128Mi

# Jupyterhub
jupyterhub:
  enabled: true

  ingress:
    enabled: false

  scheduling:
    userScheduler:
      resources:
        limits:
          cpu: 50m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 256Mi

  debug:
    enabled: false

  hub:
    extraEnv:
      - name: KC_CLIENT_SECRET
        valueFrom:
          secretKeyRef:
            name: primehub-client-jupyterhub
            key: client_secret
    extraContainers: []
    extraVolumes:
    - name: primehub-hub-images
      readOnly: true
      configMap:
        name: primehub-hub-images
    - name: primehub-hub-js
      readOnly: true
      configMap:
        name: primehub-hub-js
    - name: primehub-hub-css
      readOnly: true
      configMap:
        name: primehub-hub-css
    - name: primehub-hub-templates
      readOnly: true
      configMap:
        name: primehub-hub-templates
    - name: primehub-hub-config
      readOnly: true
      configMap:
        name: primehub-hub-config
    extraVolumeMounts:
    - name: primehub-hub-images
      mountPath: /usr/local/share/jupyterhub/static/images
    - name: primehub-hub-js
      mountPath: /usr/local/share/jupyterhub/static/components/primehub
    - name: primehub-hub-css
      mountPath: /usr/local/share/jupyterhub/static/css/primehub
    - name: primehub-hub-templates
      mountPath: /etc/jupyterhub/templates
    - name: primehub-hub-config
      mountPath: /srv/primehub
    image:
      name: infuseai/jupyterhub-k8s
      tag: jh-5c94e4f4
    networkPolicy:
      enabled: true
    extraEnv:
      - name: KC_CLIENT_SECRET
        valueFrom:
          secretKeyRef:
            key: client_secret
            name: primehub-client-jupyterhub
    extraConfig:
      primehub_config_main.py: |
        exec(open("/srv/primehub/primehub_config.py").read())
    resources:
      limits:
        cpu: 1000m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 512Mi

  proxy:
    https:
      enabled: false
    service:
      type: ClusterIP
      # this is required for switching from the default LoadBalancer install
      nodePorts:
        http: "null"
        https: "null"
    chp:
      resources:
        limits:
          cpu: 200m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 512Mi
  auth:
    state:
      enabled: true
    type: custom
    custom:
      className: OIDCAuthenticator

  singleuser:
    uid: 0
    fsGid: null
    cloudMetadata:
      enabled: true
    events: true
    networkPolicy:
      enabled: true
    extraEnv:
      JUPYTER_ENABLE_LAB: "yes"
      CULL_TIMEOUT: "7200"
      CULL_KERNEL_TIMEOUT: "3600"
      CULL_INTERVAL: "300"
      CULL_CONNECTED: "1"
    nodeSelector:
      component: singleuser-server
    image:
      name: registry.gitlab.com/aiacademy/docker-stacks/aia-notebook
      tag: latest-cpu
      pullPolicy: IfNotPresent
    cmd: null
    networkTools:
      image:
        name: jupyterhub/k8s-network-tools
        tag: 0.9-b51ffeb

  prePuller:
    hook:
      enabled: false
      image:
        name: jupyterhub/k8s-image-awaiter
        tag: 0.9-b51ffeb

  scheduling:
    userScheduler:
      resources:
        limits:
          cpu: 50m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 256Mi

  ingress:
    enabled: false

  debug:
    enabled: false

  cull:
    enabled: false

  primehub:
    keycloakClientId: jupyterhub
    scopeRequired: ''
    startnotebook: {}
    kernelGateway: false
    node-affinity-preferred: []
    node-affinity-required: []
    pod-affinity-preferred: []
    pod-affinity-required: []
    pod-anti-affinity-preferred: []
    pod-anti-affinity-required: []
    startNotebookConfigMap: start-notebook-d

# Group Volume (shared volume over nfs)
groupvolume:
  enabled: true

  replicas: 1

  image:
    repository: metacontroller/jsonnetd
    tag: 0.1
    pullPolicy: IfNotPresent

  resources:
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi
  nodeSelector: {}
  tolerations: []
  affinity: {}

  storageClass: null
  nfs:
    image:
      repository: k8s.gcr.io/volume-nfs
      tag: 0.8
      pullPolicy: IfNotPresent

# Gitsync Dataset
gitsync:
  enabled: true

  replicas: 1

  image:
    repository: metacontroller/jsonnetd
    tag: 0.1
    pullPolicy: IfNotPresent

  resources:
    limits:
      cpu: 50m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 128Mi
  nodeSelector: {}
  tolerations: []
  affinity: {}

  daemonset:
    delayInit: false
    image:
      repository: k8s.gcr.io/git-sync
      tag: v3.1.3
      pullPolicy: IfNotPresent

#                   ____________   ______           __
#                  / ____/ ____/  / ____/__  ____ _/ /___  __________  _____
#  ____________   / __/ / __/    / /_  / _ \/ __ `/ __/ / / / ___/ _ \/ ___/  ____________
# /_____/_____/  / /___/ /___   / __/ /  __/ /_/ / /_/ /_/ / /  /  __(__  )  /_____/_____/
#               /_____/_____/  /_/    \___/\__,_/\__/\__,_/_/   \___/____/


# Primehub controller
controller:
  replicaCount: 1

  image:
    repository: infuseai/primehub-controller-ee
    tag: latest

  proxy:
    image:
      repository: gcr.io/kubebuilder/kube-rbac-proxy
      tag: v0.4.1

  service:
    type: ClusterIP
    port: 8443

  resources:
    limits:
      cpu: 100m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 20Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

# Image builder
customImage:
  enabled: false
  #registryEndpoint: https://gcr.io
  #registryUsername: _json_key
  #registryPassword: _password_
  #pushRepoPrefix: gcr.io/_prefix_
  pushSecretName: primehub-controller-custom-image-push-secret

  buildJob:
    resources:
      limits:
        cpu: 2000m
        memory: 1500Mi
      requests:
        cpu: 500m
        memory: 100Mi

# Job Submission
jobSubmission:
  enabled: false
  workingDirSize: 5Gi
  defaultActiveDeadlineSeconds: 86400
  defaultTTLSecondsAfterFinished: 604800

# Model Deployment
modelDeployment:
  enabled: false
  engineContainer:
    image:
      repository: seldonio/seldon-core-executor
      tag: 1.1.0
      pullPolicy: IfNotPresent

# Admin Notebook
adminNotebook:
  enabled: false
  replicaCount: 1
  image:
    repository: infuseai/primehub-admin-notebook
    tag: dd029e8112
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP
    port: 80

  resources:
    limits:
      cpu: 1
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

# Grafana
grafana:
  enabled: false

# Keycloak gateway for admin notebook
keycloakGateway:
  image:
    repository: keycloak/keycloak-gatekeeper
    tag: 6.0.1
    pullPolicy: IfNotPresent

openshift:
  scc: false

istio:
  enabled: false
  authService:
    image:
      repository: infuseai/oidc-authservice
      tag: 1dc296d
      pullPolicy: IfNotPresent
    replicaCount: 1
    service:
      type: ClusterIP
      port: 8080

fluentd:
  enabled: false

  # Buffer configuration: https://docs.fluentd.org/configuration/buffer-section
  flushAtShutdown: false
  flushInterval: "3600s"
  chunkLimitSize: "256m"
  # XXX: will be removed when integration with primehub store
  bucket: "primehub"
  endpoint: "http://minio.hub:9000/"
  # S3 Configuratio
  storeAs: "txt"
  image:
    repository: fluent/fluentd-kubernetes-daemonset
    tag: v1.11-debian-s3-1
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 512m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 512Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

minio:
  ## Provide a name in place of minio for `app:` labels
  ##
  nameOverride: ""

  ## Provide a name to substitute for the full names of resources
  ##
  fullnameOverride: ""

  ## set kubernetes cluster domain where minio is running
  ##
  clusterDomain: cluster.local

  ## Set default image, imageTag, and imagePullPolicy. mode is used to indicate the
  ##
  image:
    repository: minio/minio
    tag: RELEASE.2020-06-14T18-32-17Z
    pullPolicy: IfNotPresent

  ## Set default image, imageTag, and imagePullPolicy for the `mc` (the minio
  ## client used to create a default bucket).
  ##
  mcImage:
    repository: minio/mc
    tag: RELEASE.2020-05-28T23-43-36Z
    pullPolicy: IfNotPresent

  ## Set default image, imageTag, and imagePullPolicy for the `jq` (the JSON
  ## process used to create secret for prometheus ServiceMonitor).
  ##
  helmKubectlJqImage:
    repository: bskim45/helm-kubectl-jq
    tag: 3.1.0
    pullPolicy: IfNotPresent

  ## minio server mode, i.e. standalone or distributed.
  ## Distributed Minio ref: https://docs.minio.io/docs/distributed-minio-quickstart-guide
  ##
  mode: standalone

  ## Additional arguments to pass to minio binary
  extraArgs: []

  ## Update strategy for Deployments
  DeploymentUpdate:
    type: RollingUpdate
    maxUnavailable: 0
    maxSurge: 100%

  ## Update strategy for StatefulSets
  StatefulSetUpdate:
    updateStrategy: RollingUpdate

  ## Pod priority settings
  ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
  ##
  priorityClassName: ""

  ## Set default accesskey, secretkey, Minio config file path, volume mount path and
  ## number of nodes (only used for Minio distributed mode)
  ## AccessKey and secretKey is generated when not set
  ## Distributed Minio ref: https://docs.minio.io/docs/distributed-minio-quickstart-guide
  ##
  existingSecret: ""
  accessKey: "AKIAIOSFODNN7EXAMPLE"
  secretKey: "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
  certsPath: "/etc/minio/certs/"
  configPathmc: "/etc/minio/mc/"
  mountPath: "/export"

  ## Override the root directory which the minio server should serve from.
  ## If left empty, it defaults to the value of {{ .Values.mountPath }}
  ## If defined, it must be a sub-directory of the path specified in {{ .Values.mountPath }}
  bucketRoot: ""

  # Number of drives attached to a node
  drivesPerNode: 1
  # Number of MinIO containers running
  replicas: 4
  # Number of expanded MinIO clusters
  zones: 1

  ## TLS Settings for Minio
  tls:
    enabled: false
    ## Create a secret with private.key and public.crt files and pass that here. Ref: https://github.com/minio/minio/tree/master/docs/tls/kubernetes#2-create-kubernetes-secret
    certSecret: ""
    publicCrt: public.crt
    privateKey: private.key

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: true

    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    existingClaim: ""

    ## minio data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    ## Storage class of PV to bind. By default it looks for standard storage class.
    ## If the PV uses a different storage class, specify that here.
    storageClass: ""
    VolumeName: ""
    accessMode: ReadWriteOnce
    size: 10Gi

    ## If subPath is set mount a sub folder of a volume instead of the root of the volume.
    ## This is especially handy for volume plugins that don't natively support sub mounting (like glusterfs).
    ##
    subPath: ""

  ## Expose the Minio service to be accessed from outside the cluster (LoadBalancer service).
  ## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.
  ## ref: http://kubernetes.io/docs/user-guide/services/
  ##

  service:
    type: ClusterIP
    clusterIP: ~
    port: 9000
    nodePort: 32000

    ## List of IP addresses at which the Prometheus server service is available
    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
    ##
    externalIPs: []
    #   - externalIp1

    annotations: {}
      # prometheus.io/scrape: 'true'
      # prometheus.io/path:   '/minio/prometheus/metrics'
      # prometheus.io/port:   '9000'

  ## Configure Ingress based on the documentation here: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ##

  imagePullSecrets: []
  # - name: "image-pull-secret"

  ingress:
    enabled: false
    labels: {}
      # node-role.kubernetes.io/ingress: platform

    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # kubernetes.io/ingress.allow-http: "false"
      # kubernetes.io/ingress.global-static-ip-name: ""
      # nginx.ingress.kubernetes.io/secure-backends: "true"
      # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      # nginx.ingress.kubernetes.io/whitelist-source-range: 0.0.0.0/0
    path: /
    hosts:
      - chart-example.local
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  ## Node labels for pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  tolerations: []
  affinity: {}

  ## Add stateful containers to have security context, if enabled MinIO will run as this
  ## user and group NOTE: securityContext is only enabled if persistence.enabled=true
  securityContext:
    enabled: true
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000

  # Additational pod annotations
  podAnnotations: {}

  # Additional pod labels
  podLabels: {}

  ## Liveness and Readiness probe values.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 1
    successThreshold: 1
    failureThreshold: 1
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 5
    ## Set this to 1s higher than MINIO_API_READY_DEADLINE
    timeoutSeconds: 6
    successThreshold: 1
    failureThreshold: 3

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources:
    requests:
      memory: 4Gi

  ## Create a bucket after minio install
  ##
  defaultBucket:
    enabled: true
    ## If enabled, must be a string with length > 0
    name: primehub
    ## Can be one of none|download|upload|public
    policy: none
    ## Purge if bucket exists already
    purge: false

  ## Create multiple buckets after minio install
  ## Enabling `defaultBucket` will take priority over this list
  ##
  buckets: []
    # - name: bucket1
    #   policy: none
    #   purge: false
    # - name: bucket2
    #   policy: none
    #   purge: false

  ## Additional Annotations for the Kubernetes Batch (make-bucket-job)
  makeBucketJob:
    annotations:

  ## Additional Annotations for the Kubernetes Batch (update-prometheus-secret)
  updatePrometheusJob:
    annotations:

  s3gateway:
    enabled: false
    replicas: 4
    serviceEndpoint: ""
    accessKey: ""
    secretKey: ""

  ## Use minio as an azure blob gateway, you should disable data persistence so no volume claim are created.
  ## https://docs.minio.io/docs/minio-gateway-for-azure
  azuregateway:
    enabled: false
    # Number of parallel instances
    replicas: 4

  ## Use minio as GCS (Google Cloud Storage) gateway, you should disable data persistence so no volume claim are created.
  ## https://docs.minio.io/docs/minio-gateway-for-gcs

  gcsgateway:
    enabled: false
    # Number of parallel instances
    replicas: 4
    # credential json file of service account key
    gcsKeyJson: ""
    # Google cloud project-id
    projectId: ""

  ossgateway:
    enabled: false
    # Number of parallel instances
    replicas: 4
    endpointURL: ""

  ## Use minio on NAS backend
  ## https://docs.minio.io/docs/minio-gateway-for-nas

  nasgateway:
    enabled: false
    # Number of parallel instances
    replicas: 4
    # For NAS Gateway, you may want to bind the PVC to a specific PV. To ensure that happens, PV to bind to should have
    # a label like "pv: <value>", use value here.
    pv: ~

  ## Use minio as Backblaze B2 gateway
  ## https://github.com/minio/minio/blob/master/docs/gateway/b2.md
  b2gateway:
    enabled: false
    # Number of parallel instances
    replicas: 4

  ## Use this field to add environment variables relevant to Minio server. These fields will be passed on to Minio container(s)
  ## when Chart is deployed
  environment:
    MINIO_API_READY_DEADLINE: "5s"
    ## Please refer for comprehensive list https://docs.minio.io/docs/minio-server-configuration-guide.html

  networkPolicy:
    enabled: false
    allowExternal: true

  ## PodDisruptionBudget settings
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  ##
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 1

  ## Specify the service account to use for the Minio pods. If 'create' is set to 'false'
  ## and 'name' is left unspecified, the account 'default' will be used.
  serviceAccount:
    create: true
    ## The name of the service account to use. If 'create' is 'true', a service account with that name
    ## will be created. Otherwise, a name will be auto-generated.
    name:

  metrics:
    # Metrics can not be disabled yet: https://github.com/minio/minio/issues/7493
    serviceMonitor:
      enabled: false
      additionalLabels: {}
      # namespace: monitoring
      # interval: 30s
      # scrapeTimeout: 10s

  ## ETCD settings: https://github.com/minio/minio/blob/master/docs/sts/etcd.md
  etcd:
    endpoints: []
    pathPrefix: ""
    corednsPathPrefix: ""
    clientCert: ""
    clientCertKey: ""

